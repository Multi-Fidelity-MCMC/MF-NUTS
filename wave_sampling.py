from mf_sampling import MF_Sampling
import forward_models
import save_functions
import wave_specs

import numpy as np
import scipy.special as sc
from scipy.stats import multivariate_normal
from jax import numpy as jnp, config, jacfwd

config.update("jax_enable_x64", True)


# This is an extra function that can be accessed outside the class
def detransform_samples(transformed_filename, new_filename):
    """ Saves an additional file with detransformed samples in sample space. """

    (
        all_model_samples,
        all_model_obs,
        all_model_log_probs,
        total_time,
        total_acc_ratio,
        model_eval_counts,
        model_acc_ratios,
        acc_history,
        grid_sizes,
        current_obs,
        current_ll,
        adaptive_matrix,
        epsilon,
        tree_depth,
        nuts_time,
    ) = save_functions.load_data(transformed_filename)

    # For single chains, we need to add another dimension
    if len(all_model_samples.shape) <= 3:
        all_model_samples = np.expand_dims(all_model_samples, axis=0)

    exponential_samples = np.exp(all_model_samples)

    logit_inv_samples = exponential_samples / (1 + exponential_samples)

    new_samples = np.array([
            wave_specs.XMIN
            + (wave_specs.XMAX - wave_specs.XMIN) * logit_inv_samples[:, :, :, 0],
            wave_specs.YMIN
            + (wave_specs.YMAX - wave_specs.YMIN) * logit_inv_samples[:, :, :, 1],
            wave_specs.XMIN
            + (wave_specs.XMAX - wave_specs.XMIN) * logit_inv_samples[:, :, :, 2],
            wave_specs.YMIN
            + (wave_specs.YMAX - wave_specs.YMIN) * logit_inv_samples[:, :, :, 3],
            all_model_samples[:, :, :, 4],
            all_model_samples[:, :, :, 5],
            logit_inv_samples[:, :, :, 6],
        ])

    new_samples = np.moveaxis(new_samples, 0, -1)

    save_functions.save_data(
        new_filename,
        new_samples,
        all_model_obs,
        all_model_log_probs,
        total_time,
        total_acc_ratio,
        model_eval_counts,
        model_acc_ratios,
        acc_history,
        grid_sizes,
        current_obs,
        current_ll,
        adaptive_matrix,
        epsilon,
        tree_depth,
        nuts_time,
    )


class Wave_Sampling(MF_Sampling):
    """ A class for multi-fidelity sampling to solve the inverse wave problem.
    Inherits from the MF_Sampling class.

    NOTE: In addition to the six methods specifically required to be overwritten,
    we also overwrite the following methods:
        compute_current_log_prior()
        compute_new_log_prior()
        rw_acceptance_probability()
        compute_current_hmc_log_posterior()
        compute_new_hmc_log_posterior()
    In this class, we transform the sample space, and we implement log_prior() to
    compute and return the log determinant of the Jacobian of this transformation.
    We save this value as an attribute, which must be applied to the log posterior
    distribution, which is why we must overwrite each of these methods.
    """

    def __init__(
        self,
        current_sample,
        current_sample_obs,
        current_sample_lls,
        sample_mean,
        grid_sizes,
        adaptive_matrix=None,
        epsilon=None,
    ):
        """ Initializes the Wave_Sampling class.

        grid_sizes (list):
            A list of length num_models that indicates the gridsize used by each 
            forward model to solve the wave equation.
        """

        self.grid_sizes = grid_sizes
        self.num_models = len(grid_sizes)

        # We need to calculate the buoy indices for each grid_size
        self.model_buoys = np.array([
                [
                    forward_models.get_buoy(buoy_rat[0], buoy_rat[1], grid_size)
                    for buoy_rat in wave_specs.BUOY_RATS
                ]
                for grid_size in grid_sizes
            ])

        _, self.dt = np.linspace(0, wave_specs.T, wave_specs.TIMESTEPS, retstep=True)

        MF_Sampling.__init__(
            self,
            current_sample,
            current_sample_obs,
            current_sample_lls,
            sample_mean,
            len(grid_sizes),
            adaptive_matrix,
            epsilon,
        )

        self.model_labels = (
            grid_sizes  # Overwrite to "label" each forward model by its grid_size
            )


    def initialize_sample_obs_lls(self, initial_sample, num_models):
        """ Initialize the current state with its observations and likelihoods 
        generated by each forward model.
        """

        # Make sure that the sample is valid
        if self.sample_not_valid(initial_sample):
            raise ValueError(
                "The initial sample is not valid. Please input a sample that lies within the problem specifications."
                )

        # Transform sample given in sample space to logit space
        td_initial_sample = self.transform_sample(initial_sample)

        model_likelihoods = []
        model_observations = []

        for model in range(num_models):
            likelihood, observation = self.log_likelihood(td_initial_sample, model)

            # Make sure that the likelihood is not -infinity
            if np.isinf(likelihood):
                raise ValueError(
                    "The initial sample has an infinite likelihood. Please input a better sample."
                    )

            model_likelihoods.append(likelihood)
            model_observations.append(observation)

        return (
            np.array(td_initial_sample),
            np.array(model_observations),
            np.array(model_likelihoods),
        )


    ######################################################################
    # GENERAL HELPER FUNCTIONS
    ######################################################################


    def sample_not_valid(self, sample):
        """ Returns bool indicating if sample is an invalid sample or not 
        (True = invalid). The sample must be of form 
            [mean_11, mean_12, mean_21, mean_22, coeff_1, coeff_2, c].
        Assumes sample is in sample space.
        """

        # Check if c value is within proper bounds
        if sample[-1] > 1 or sample[-1] < 0:
            return True
        # Check if x-coords of means is within proper bounds
        elif (np.array([sample[0], sample[2]]) > wave_specs.XMAX).any() or (
                np.array([sample[0], sample[2]]) < wave_specs.XMIN
            ).any():
            return True
        # Check if y-coords of means is within proper bounds
        elif (np.array([sample[1], sample[3]]) > wave_specs.YMAX).any() or (
                np.array([sample[1], sample[3]]) < wave_specs.YMIN
            ).any():
            return True
        else:
            return False


    def log_prior(self, td_sample, return_log_jac=False):
        """ Computes the log prior probability of the given transformed sample. 
        All parameters have Gaussian priors except for c, which is 
        Beta(PRIOR_A, PRIOR_B)

        THIS FUNCTION ASSUMES THAT TD_SAMPLE IS IN LOGIT SPACE!!!

        Parameters
        ----------
        td_sample (ndarray):
            A sample drawn from logit space of the (transformed) form
            [mean_11, mean_12, mean_21, mean_22, coeff_1, coeff_2, c]
        return_log_jac (bool):
            Indicates whether to return log_jacobian_det

        Returns
        -------
        log_prior_prob (float):
            The log prior probability of the given sample
        log_jacobian_det (float):
            The log determinant of the Jacobian of the inverse parameter transform
            (if specified)
        """

        sample, jacobian_det, _, _ = self.bring_back_sample(
            td_sample, return_jacobian_info=True
            )

        # This is somehow faster than the scipy.stats implementation?
        beta_log_pdf = lambda x, a, b: np.log(
            x ** (a - 1) * (1 - x) ** (b - 1) / sc.beta(a, b)
            )

        log_prior_prob = multivariate_normal.logpdf(
            sample[:-1],
            mean=wave_specs.PRIOR_MEAN,
            cov=np.diag(wave_specs.PRIOR_COV_DIAG),
            ) + beta_log_pdf(sample[-1], wave_specs.PRIOR_A, wave_specs.PRIOR_B)

        if return_log_jac:
            return log_prior_prob, np.log(jacobian_det)
        else:
            return log_prior_prob


    def compute_current_log_prior(self, current_sample):
        """ Overwrites base function to also save jacobian info. """
        self.current_log_prior, self.current_log_jac = self.log_prior(
            current_sample, return_log_jac=True
            )


    def compute_new_log_prior(self, new_sample):
        """ Overwrites base function to also save jacobian info. """
        self.new_log_prior, self.new_log_jac = self.log_prior(
            new_sample, return_log_jac=True
            )


    def forward(self, params, model):
        """ Solves the forward wave problem given by

        u_tt - c^2(u_xx + u_yy) = 0
        u(t=0) = f, u_t(t=0) = 0
        u(x=x_min) = u(x=x_max) = u(y=y_min) = u(y=y_max) = 0

        Parameters
        ----------
        params (ndarray):
            List of parameters over which to define the wave propagation
        model (int):
            Indicates which forward model to evaluate to compute the likelihood,
            and ranges in [0, self.num_models]

        Returns
        -------
        wave_sols (ndarray):
            The entire wave simulation for all timesteps
        """

        return forward_models.wave_solver(
            params,
            wave_specs.XMIN,
            wave_specs.XMAX,
            wave_specs.YMIN,
            wave_specs.YMAX,
            self.grid_sizes[model],
            self.dt,
            wave_specs.TIMESTEPS,
        )


    def log_likelihood(self, td_sample, model, return_wave_sols=False):
        """ Computes the log likelihood and forward model observations of the 
        given transformed sample.

        THIS FUNCTION ASSUMES THAT TD_SAMPLE IS IN LOGIT SPACE!!!

        Parameters
        ----------
        td_sample (ndarray):
            A sample drawn from logit space of the (transformed) form
            [mean_11, mean_12, mean_21, mean_22, coeff_1, coeff_2, c]
        model (int):
            Indicates which forward model to evaluate to compute the likelihood,
            and ranges in [0, self.num_models]
        return_wave_sols (bool):
            Indicates whether to return wave_sols

        Returns
        -------
        sample_ll (float):
            The log likelihood of the given sample
        sample_obs (ndarray):
            The observations returned by the forward model used to compute the
            likelihood
        wave_sols (ndarray):
            The entire wave simulation for all timesteps (if specified)
        """

        sample = self.bring_back_sample(td_sample)

        wave_sols = self.forward(sample, model)

        # Find the times and wave heights at which the waves are highest using this model's buoys
        heights, times = forward_models.get_observations(
            wave_sols, self.model_buoys[model]
            )
        self.time_indices = times  # Set the arrival time indices for future use

        times_secs = (
            (times + 1) / wave_specs.TIMESTEPS * wave_specs.T
            )  # Convert time frames to seconds
        sample_obs = np.hstack(
            (heights, times_secs)
            )  # Append corresponding times to wave heights

        sample_ll = multivariate_normal.logpdf(
            wave_specs.ALL_OBS, mean=sample_obs, cov=np.diag(wave_specs.LL_COV_DIAG)
            )

        if return_wave_sols:
            return sample_ll, sample_obs, wave_sols
        else:
            return sample_ll, sample_obs


    ######################################################################
    # TRACKER FUNCTIONS
    ######################################################################


    def add_data(self, save_filename):
        """ Adds all data to an existing file called save_filename by wrapping 
        the function imported from save_functions.
        """
        save_functions.add_data(
            save_filename,
            np.array(self.all_model_samples),
            np.array(self.all_model_obs),
            np.array(self.all_model_log_probs),
            self.overall_time,
            self.all_model_times,
            self.overall_acc_ratio,
            self.model_eval_counter,
            self.model_acceptances,
            np.array(self.acceptance_history),
            self.model_labels,
            self.current_sample_obs,
            self.current_sample_lls,
            self.adaptive_matrix,
            self.epsilon,
            self.average_tree_depth,
        )


    def save_data(self, save_filename):
        """ Saves all data to a new file called save_filename by wrapping the 
        function imported from save_functions.
        """
        save_functions.save_data(
            save_filename,
            np.array(self.all_model_samples),
            np.array(self.all_model_obs),
            np.array(self.all_model_log_probs),
            self.overall_time,
            self.all_model_times,
            self.overall_acc_ratio,
            self.model_eval_counter,
            self.model_acceptances,
            np.array(self.acceptance_history),
            self.model_labels,
            self.current_sample_obs,
            self.current_sample_lls,
            self.adaptive_matrix,
            self.epsilon,
            self.average_tree_depth,
        )


    ######################################################################
    # TRANSFORMATION FUNCTIONS
    ######################################################################


    def transform_sample(self, sample):
        """ Transforms the given sample into logit space. """
        logit = lambda x: np.log(x / (1 - x))

        return np.array([
            logit(
                (sample[0] - wave_specs.XMIN) / (wave_specs.XMAX - wave_specs.XMIN)
            ),
            logit(
                (sample[1] - wave_specs.YMIN) / (wave_specs.YMAX - wave_specs.YMIN)
            ),
            logit(
                (sample[2] - wave_specs.XMIN) / (wave_specs.XMAX - wave_specs.XMIN)
            ),
            logit(
                (sample[3] - wave_specs.YMIN) / (wave_specs.YMAX - wave_specs.YMIN)
            ),
            sample[4],
            sample[5],
            logit(sample[6]),
        ])


    def logit_inv(self, td_sample):
        """ The inverse logit transform. """
        exponent = np.exp(td_sample)
        return exponent / (1 + exponent)


    def bring_back_sample(self, td_sample, return_jacobian_info=False):
        """ Transforms samples from logit space back into the original parameter 
        space. The td_sample must be an array of the form
        [mean_11, mean_12, mean_21, mean_22, coeff_1, coeff_2, c].
        """

        logit_inv_td_sample = self.logit_inv(td_sample)

        sample = np.array([
                wave_specs.XMIN
                + (wave_specs.XMAX - wave_specs.XMIN) * logit_inv_td_sample[0],
                wave_specs.YMIN
                + (wave_specs.YMAX - wave_specs.YMIN) * logit_inv_td_sample[1],
                wave_specs.XMIN
                + (wave_specs.XMAX - wave_specs.XMIN) * logit_inv_td_sample[2],
                wave_specs.YMIN
                + (wave_specs.YMAX - wave_specs.YMIN) * logit_inv_td_sample[3],
                td_sample[4],
                td_sample[5],
                logit_inv_td_sample[6],
            ])

        if not return_jacobian_info:
            return sample

        else:
            # These are the diagonal entries of the Jacobian
            derivatives = np.array([
                    (wave_specs.XMAX - wave_specs.XMIN)
                    * logit_inv_td_sample[0]
                    * (1 - logit_inv_td_sample[0]),
                    (wave_specs.YMAX - wave_specs.YMIN)
                    * logit_inv_td_sample[1]
                    * (1 - logit_inv_td_sample[1]),
                    (wave_specs.XMAX - wave_specs.XMIN)
                    * logit_inv_td_sample[2]
                    * (1 - logit_inv_td_sample[2]),
                    (wave_specs.YMAX - wave_specs.YMIN)
                    * logit_inv_td_sample[3]
                    * (1 - logit_inv_td_sample[3]),
                    1.0,
                    1.0,
                    logit_inv_td_sample[6] * (1 - logit_inv_td_sample[6]),
                ])

            return sample, np.prod(derivatives), logit_inv_td_sample, derivatives


    ######################################################################
    # SAMPLER-SPECIFIC HELPER FUNCTIONS
    ######################################################################


    def rw_acceptance_probability(self, current_sample_ll, new_sample_ll):
        """ Overwrites the base function to include transformation correction. """

        return (
            new_sample_ll
            + self.new_log_prior
            + self.new_log_jac
            - current_sample_ll
            - self.current_log_prior
            - self.current_log_jac
        )


    def compute_current_hmc_log_posterior(self, current_p, current_ll):
        """ Overwrites the base function to include transformation correction. """
        self.current_hmc_log_posterior = (
            current_ll
            + self.current_log_prior
            + self.current_log_jac
            - np.sum(current_p**2 / self.adaptive_matrix) / 2
            )


    def compute_new_hmc_log_posterior(self, new_p, new_ll):
        """ Overwrites the base function to include transformation correction. """
        self.new_hmc_log_posterior = (
            new_ll
            + self.new_log_prior
            + self.new_log_jac
            - np.sum(new_p**2 / self.adaptive_matrix) / 2
            )


    def derivative_log_density(self, td_sample, model):
        """ Computes the derivative of the log density evaluated at the given
        transformed sample.

        THIS FUNCTION ASSUMES THAT TD_SAMPLE IS IN LOGIT SPACE!!!

        Parameters
        ----------
        td_sample (ndarray):
            A sample drawn from logit space
        model (int):
            Indicates which forward model to use for the likelihood,
            and ranges in [0, self.num_models]

        Returns
        -------
        gradient (ndarray):
            The gradient of the log density at the given sample
        td_sample_ll (float):
            The log likelihood of the given transformed sample
        sample_ob (ndarray):
            The observations returned by the forward model used to compute the
            likelihood
        """
        # Transform sample from logit space back to sample space
        sample, _, logit_inv_td_sample, d_td_sample = self.bring_back_sample(
            td_sample, return_jacobian_info=True
            )

        td_sample_ll, sample_ob, wave_sols = self.log_likelihood(
            td_sample, model, return_wave_sols=True
            )

        # If the likelihood is (negative) infinity, break out now
        if np.isinf(td_sample_ll):
            print("INFINITE LIKELIHOOD!!!")
            return 0, td_sample_ll, 0

        # Compute the derivative of the likelihood with respect to wave heights 
        # and arrival times. Both d_L_waves and d_L_times have size num_buoys
        d_L_waves, d_L_times = self.derivative_likelihood_observations(sample_ob)

        # Compute the derivative (and offsets) of the wave heights with respect 
        # to the given sample. d_waves_sample has size num_buoys x num_params
        d_waves_sample, d_waves_sample_offset_1, d_waves_sample_offset_2 = (
            self.derivative_wave_heights_sample(sample, model)
            )

        d_waves_sample, d_waves_sample_offset_1, d_waves_sample_offset_2 = (
            np.asarray(d_waves_sample),
            np.asarray(d_waves_sample_offset_1),
            np.asarray(d_waves_sample_offset_2),
            )
        # Compute the derivative of the arrival times with respect to the given 
        # sample. d_time_sample has size num_buoys x num_params
        d_time_sample = self.derivative_time_sample(
            wave_sols,
            d_waves_sample,
            d_waves_sample_offset_1,
            d_waves_sample_offset_2,
            model,
            )

        # Do NOT divide out by prior since that was taken care of before in 
        # derivative_prior()
        gradient = np.sum([
                -(d_L_waves[i] * d_waves_sample[i] + d_L_times[i] * d_time_sample[i])
                for i in range(d_L_waves.shape[0])
            ], axis=0,) - self.derivative_prior_sample(sample)

        # Logit transform correction
        # We initialize the jacobian part as 0s since the coeff_1 and coeff_2 
        # parts will remain 0
        jacobian_part = np.zeros_like(
            sample
            )  
        mask = [0, 1, 2, 3, 6]  # Do not transform coeff_1 or coeff_2 (indices 4 and 5)
        jacobian_part[mask] = logit_inv_td_sample[mask] * (np.exp(-td_sample[mask]) - 1)

        gradient = gradient * d_td_sample - jacobian_part

        return gradient, td_sample_ll, sample_ob


    def derivative_likelihood_observations(self, observations):
        """ Computes the derivative of the likelihood with respect to each
        observation. Returns the derivatives with respect to wave height
        observations and arrival time observations separately.
        """

        var = wave_specs.LL_COV_DIAG[: observations.shape[0]]
        # Do NOT multiply by ll since it will be divided out later
        obs = (wave_specs.ALL_OBS - observations) / var

        # Returns (dL/dW, dL/dT)
        return obs[: wave_specs.OBS_VALS.shape[0]], obs[wave_specs.OBS_VALS.shape[0] :]


    def derivative_wave_heights_sample(self, sample, model):
        """ Computes the derivative of the wave height observations with respect 
        to the given sample. Assumes the given sample is in sample space.

        Returns three values of dW/dq that are offset in time either before or 
        after the actual timestep to permit FD approximations of the time 
        derivative later.
        """

        # Compute the Jacobian with Auto Differentiation
        func = lambda parameters: self.forward(parameters, model)
        jacobian = jacfwd(func)(jnp.array(sample))

        d_waves, d_waves_offset_1, d_waves_offset_2 = [], [], []
        for i in range(self.time_indices.shape[0]):  # The number of observation buoys
            # Recall that buoys is listed as [x-coord, y-coord]
            d_waves.append(
                jacobian[
                    self.time_indices[i],
                    self.model_buoys[model, i, 1],
                    self.model_buoys[model, i, 0],
                ])

            if self.time_indices[i] >= 3:
                # If the observation has a late-enough time, save previous times 
                # for a backward FD scheme
                d_waves_offset_1.append(
                    jacobian[
                        self.time_indices[i] - 1,
                        self.model_buoys[model, i, 1],
                        self.model_buoys[model, i, 0],
                    ])
                d_waves_offset_2.append(
                    jacobian[
                        self.time_indices[i] - 2,
                        self.model_buoys[model, i, 1],
                        self.model_buoys[model, i, 0],
                    ])

            else:
                # If the observation has an early time, save following times for 
                # a forward FD scheme
                d_waves_offset_1.append(
                    jacobian[
                        self.time_indices[i] + 1,
                        self.model_buoys[model, i, 1],
                        self.model_buoys[model, i, 0],
                    ])
                d_waves_offset_2.append(
                    jacobian[
                        self.time_indices[i] + 2,
                        self.model_buoys[model, i, 1],
                        self.model_buoys[model, i, 0],
                    ])

        return np.array(d_waves), np.array(d_waves_offset_1), np.array(d_waves_offset_2)

    def derivative_time_sample(
        self, wave_sols, d_waves, d_waves_offset_1, d_waves_offset_2, model
    ):
        """ Computes the derivative of the arrival times with respect to the 
        sample. Assumes the sample in sample space.
        """

        # Default to forward FD scheme and change later if necessary 
        # (the difference is -1)
        numerators = (-3 * d_waves + 4 * d_waves_offset_1 - d_waves_offset_2) / (
            2 * self.dt
            )

        for i in range(self.time_indices.shape[0]):  # The number of observation buoys
            if self.time_indices[i] >= 3:
                # If we're doing a backward FD scheme for the numerator, we need 
                # to multiply it by -1
                numerators[i] *= -1

            if self.time_indices[i] >= 4:
                # If the observation has a late-enough time, use a backward FD 
                # scheme for the denominator
                # Recall that buoys is listed as [x-coord, y-coord]
                U_frames = wave_sols[
                    self.time_indices[i] - 3 : self.time_indices[i] + 1,
                    self.model_buoys[model, i, 1],
                    self.model_buoys[model, i, 0],
                    ]
                denom = (
                    2 * U_frames[3] - 5 * U_frames[2] + 4 * U_frames[1] - U_frames[0]
                    ) / (self.dt**2)

            else:
                # If the observations has an early time, use a forward FD scheme 
                # for the denominator
                # Recall that buoys is listed as [x-coord, y-coord]
                U_frames = wave_sols[
                    self.time_indices[i] : self.time_indices[i] + 4,
                    self.model_buoys[model, i, 1],
                    self.model_buoys[model, i, 0],
                ]
                denom = (
                    2 * U_frames[0] - 5 * U_frames[1] + 4 * U_frames[2] - U_frames[3]
                    ) / (self.dt**2)

            numerators[i] = -numerators[i] / denom

        return numerators


    def derivative_prior_sample(self, sample):
        """ Computes the derivative of the prior with respect to the given sample.
        Assumes the given sample is in sample space.
        """

        # This is somehow faster than the scipy.stats implementation?
        beta_pdf = lambda x, a, b: x ** (a - 1) * (1 - x) ** (b - 1) / sc.beta(a, b)
        # The derivative of the beta distribution pdf with respect to x
        d_beta_pdf = (
            lambda x, a, b: x ** (a - 2)
            * (1 - x) ** (b - 2)
            * ((1 - b) * x + (a - 1) * (1 - x))
            / sc.beta(a, b)
            )

        derivative = np.zeros_like(sample)

        # Do NOT multiply by the prior since it would be divided out later in 
        # derivative_log_density()
        derivative[:-1] = (
            wave_specs.PRIOR_MEAN - sample[:-1]
            ) / wave_specs.PRIOR_COV_DIAG

        # We divide by the beta pdf for the last term now instead of in 
        # derivative_log_density()
        derivative[-1] = d_beta_pdf(
            sample[-1], wave_specs.PRIOR_A, wave_specs.PRIOR_B
            ) / beta_pdf(sample[-1], wave_specs.PRIOR_A, wave_specs.PRIOR_B)

        return derivative
